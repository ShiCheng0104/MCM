# ğŸŒŸ DWTS è§‚ä¼—æŠ•ç¥¨ä¼°è®¡æ¨¡å‹ (Problem C - Task 1)

> **2026 MCM Problem C: Data With The Stars**  
> æœ¬é¡¹ç›®å®ç°äº†å¯¹ã€Šä¸æ˜Ÿå…±èˆã€‹(Dancing with the Stars) èŠ‚ç›®ä¸­è§‚ä¼—æŠ•ç¥¨æ•°çš„æ•°å­¦å»ºæ¨¡ä¸ä¼°è®¡ã€‚

---

## ğŸ“‹ é—®é¢˜èƒŒæ™¯

ã€Šä¸æ˜Ÿå…±èˆã€‹æ˜¯ç¾å›½è‘—åçœŸäººç§€èŠ‚ç›®ï¼Œè§‚ä¼—æŠ•ç¥¨ä¸è¯„å§”è¯„åˆ†å…±åŒå†³å®šé€‰æ‰‹çš„å»ç•™ã€‚ç„¶è€Œï¼Œ**è§‚ä¼—æŠ•ç¥¨æ•°ä»æœªå…¬å¼€**ï¼Œè¿™ä¸ºæ•°æ®åˆ†æå¸¦æ¥äº†æŒ‘æˆ˜ã€‚

æœ¬é¡¹ç›®çš„ç›®æ ‡æ˜¯ï¼š
- å¼€å‘æ•°å­¦æ¨¡å‹ä¼°ç®—æ¯ä½é€‰æ‰‹åœ¨æ¯å‘¨è·å¾—çš„è§‚ä¼—æŠ•ç¥¨æ•°
- é‡åŒ–ä¼°è®¡ç»“æœçš„ä¸ç¡®å®šæ€§
- éªŒè¯æ¨¡å‹ä¸å®é™…æ·˜æ±°ç»“æœçš„ä¸€è‡´æ€§

### æŠ•ç¥¨è§„åˆ™æ¼”å˜

| èµ›å­£ | è®¡åˆ†æ–¹æ³• | è¯´æ˜ |
|:----:|:--------:|------|
| S1-S2 | æ’åæ³• (Rank-based) | è¯„å§”æ’å + è§‚ä¼—æ’å |
| S3-S27 | ç™¾åˆ†æ¯”æ³• (Percentage-based) | è¯„å§”å¾—åˆ†å æ¯” + è§‚ä¼—ç¥¨æ•°å æ¯” |
| S28-S34 | æ’åæ³• + è¯„å§”æŠ•ç¥¨ | ç»¼åˆæ’åæœ€ä½ä¸¤äººç”±è¯„å§”æŠ•ç¥¨å†³å®š |

---

## ğŸ—ï¸ é¡¹ç›®ç»“æ„

```
yanxiao/
â”œâ”€â”€ ğŸ“„ README.md                     # é¡¹ç›®è¯´æ˜æ–‡æ¡£
â”œâ”€â”€ ğŸš€ main.py                       # ä¸»ç¨‹åºå…¥å£
â”œâ”€â”€ âš™ï¸ config.py                     # é…ç½®å‚æ•°æ¨¡å—
â”œâ”€â”€ ğŸ“‹ requirements.txt              # Pythonä¾èµ–
â”‚
â”œâ”€â”€ ğŸ“ data/                         # æ•°æ®æ¨¡å—
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ ğŸ“ src/                          # æ ¸å¿ƒæºä»£ç 
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_preprocessing.py       # æ•°æ®é¢„å¤„ç†
â”‚   â”œâ”€â”€ vote_estimator.py           # æŠ•ç¥¨ä¼°è®¡å™¨ï¼ˆæ•´åˆå¤šæ¨¡å‹ï¼‰
â”‚   â”œâ”€â”€ consistency_check.py        # ä¸€è‡´æ€§æ£€éªŒ
â”‚   â”œâ”€â”€ uncertainty_measure.py      # ä¸ç¡®å®šæ€§åº¦é‡
â”‚   â””â”€â”€ utils.py                    # å·¥å…·å‡½æ•°åº“
â”‚
â”œâ”€â”€ ğŸ“ models/                       # æ•°å­¦æ¨¡å‹
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ baseline_model.py           # åŸºçº¿æ¨¡å‹
â”‚   â”œâ”€â”€ constrained_optimization.py # çº¦æŸä¼˜åŒ–æ¨¡å‹
â”‚   â””â”€â”€ bayesian_model.py           # è´å¶æ–¯å±‚æ¬¡æ¨¡å‹
â”‚
â”œâ”€â”€ ğŸ“ visualization/                # å¯è§†åŒ–æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ plots.py                    # ç»‘å›¾å‡½æ•°
â”‚
â””â”€â”€ ğŸ“ outputs/                      # è¾“å‡ºç»“æœ
    â”œâ”€â”€ vote_estimates.csv          # æŠ•ç¥¨ä¼°è®¡ç»“æœ
    â”œâ”€â”€ consistency_results.csv     # ä¸€è‡´æ€§æ£€éªŒç»“æœ
    â””â”€â”€ figures/                    # å¯è§†åŒ–å›¾è¡¨
```

---

## ğŸ”§ å®‰è£…ä¸è¿è¡Œ

### ç¯å¢ƒè¦æ±‚

- Python 3.9+
- æ¨èä½¿ç”¨è™šæ‹Ÿç¯å¢ƒ

### å®‰è£…æ­¥éª¤

```bash
# 1. è¿›å…¥é¡¹ç›®ç›®å½•
cd d:/ç«èµ›/ç¾èµ›/yanxiao

# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆå¯é€‰ï¼‰
python -m venv venv
venv\Scripts\activate  # Windows

# 3. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 4. è¿è¡Œä¸»ç¨‹åº
python main.py
```

### ä¾èµ–åŒ…è¯´æ˜

| åŒ…å | ç”¨é€” |
|------|------|
| `pandas` | æ•°æ®å¤„ç† |
| `numpy` | æ•°å€¼è®¡ç®— |
| `scipy` | ä¼˜åŒ–ç®—æ³• |
| `pymc` | è´å¶æ–¯æ¨æ–­ (MCMC) |
| `arviz` | è´å¶æ–¯è¯Šæ–­ä¸å¯è§†åŒ– |
| `matplotlib` / `seaborn` | å¯è§†åŒ– |

---

## ï¿½ï¸ æ•°æ®å¤„ç†è¯¦è§£

### åŸå§‹æ•°æ®ç»“æ„

æ•°æ®æ–‡ä»¶ `2026_MCM_Problem_C_Data.csv` åŒ…å« **422 æ¡é€‰æ‰‹è®°å½•**ï¼Œè·¨è¶Š **34 ä¸ªèµ›å­£**ã€‚

| å­—æ®µ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `celebrity_name` | string | æ˜æ˜Ÿé€‰æ‰‹å§“å |
| `ballroom_partner` | string | ä¸“ä¸šèˆä¼´å§“å |
| `celebrity_industry` | string | é€‰æ‰‹æ‰€å±è¡Œä¸šï¼ˆæ¼”å‘˜ã€è¿åŠ¨å‘˜ã€æ­Œæ‰‹ç­‰ï¼‰ |
| `celebrity_age_during_season` | int | å‚èµ›æ—¶å¹´é¾„ |
| `celebrity_homecountry/region` | string | é€‰æ‰‹å›½ç±/åœ°åŒº |
| `season` | int | èµ›å­£ç¼–å· (1-34) |
| `results` | string | æ¯”èµ›ç»“æœï¼ˆå¦‚ "Eliminated Week 3", "1st Place"ï¼‰ |
| `placement` | int | æœ€ç»ˆåæ¬¡ |
| `week{n}_judge{m}_score` | float | ç¬¬nå‘¨ç¬¬mä½è¯„å§”çš„æ‰“åˆ† |

### æ•°æ®é¢„å¤„ç†æµç¨‹

```
åŸå§‹CSV â”€â”€â†’ æ•°æ®æ¸…æ´— â”€â”€â†’ ç‰¹å¾å·¥ç¨‹ â”€â”€â†’ æ ¼å¼è½¬æ¢ â”€â”€â†’ æ¨¡å‹è¾“å…¥
```

#### Step 1: æ•°æ®åŠ è½½ä¸ç±»å‹è½¬æ¢

```python
# åŠ è½½åŸå§‹æ•°æ®
df = pd.read_csv(data_path)

# å°†è¯„å§”å¾—åˆ†åˆ—è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
# åŸå§‹æ•°æ®ä¸­ "N/A" è¡¨ç¤ºæ— æ•°æ®ï¼ˆæ— ç¬¬4è¯„å§”æˆ–å·²æ·˜æ±°ï¼‰
score_columns = [col for col in df.columns if 'judge' in col and 'score' in col]
for col in score_columns:
    df[col] = pd.to_numeric(df[col], errors='coerce')  # "N/A" â†’ NaN
```

#### Step 2: æ´¾ç”Ÿç‰¹å¾æå–

ä» `results` å­—æ®µè§£æå…³é”®ä¿¡æ¯ï¼š

```python
def extract_elimination_week(result_str):
    """
    è§£ææ·˜æ±°å‘¨æ¬¡
    - "Eliminated Week 3" â†’ 3
    - "1st Place" â†’ None (å†³èµ›é€‰æ‰‹)
    - "Withdrew Week 5" â†’ None (é€€èµ›é€‰æ‰‹)
    """
    if 'Place' in result_str:
        return None  # å†³èµ›é€‰æ‰‹
    if 'Withdrew' in result_str:
        return None  # é€€èµ›
    match = re.search(r'Week (\d+)', result_str)
    return int(match.group(1)) if match else None

# æ·»åŠ æ´¾ç”Ÿç‰¹å¾
df['elimination_week'] = df['results'].apply(extract_elimination_week)
df['is_finalist'] = df['results'].str.contains('Place', na=False)
df['is_withdrew'] = df['results'].str.contains('Withdrew', na=False)
df['is_domestic'] = df['celebrity_homecountry/region'] == 'United States'
```

#### Step 3: å‘¨å¾—åˆ†èšåˆ

è®¡ç®—æ¯å‘¨çš„è¯„å§”æ€»åˆ†å’Œå¹³å‡åˆ†ï¼š

```python
def compute_weekly_total_score(row, week):
    """
    è®¡ç®—ç¬¬weekå‘¨çš„è¯„å§”æ€»åˆ†
    - è·³è¿‡ NaN å’Œ 0ï¼ˆå·²æ·˜æ±°çš„æ ‡è®°ï¼‰
    - å¤„ç†å¤šèˆå¹³å‡åˆ†ï¼ˆå°æ•°å€¼ï¼‰
    """
    total = 0
    for judge in range(1, 5):  # æœ€å¤š4ä½è¯„å§”
        col = f'week{week}_judge{judge}_score'
        if col in row.index:
            val = row[col]
            if pd.notna(val) and val > 0:
                total += float(val)
    return total

# ä¸ºæ¯å‘¨è®¡ç®—å¾—åˆ†
for week in range(1, 12):  # æœ€å¤š11å‘¨
    df[f'week{week}_total'] = df.apply(
        lambda row: compute_weekly_total_score(row, week), axis=1
    )
```

#### Step 4: é•¿æ ¼å¼è½¬æ¢

å°†å®½è¡¨è½¬æ¢ä¸ºå‘¨çº§åˆ«çš„é•¿è¡¨ï¼Œä¾¿äºæ¨¡å‹å¤„ç†ï¼š

```python
# åŸå§‹: æ¯è¡Œä¸€ä¸ªé€‰æ‰‹ï¼ŒåŒ…å«æ‰€æœ‰å‘¨çš„å¾—åˆ†
# è½¬æ¢: æ¯è¡Œä¸€ä¸ªé€‰æ‰‹åœ¨ä¸€å‘¨çš„æ•°æ®

records = []
for _, row in df.iterrows():
    for week in range(1, 12):
        total_score = row[f'week{week}_total']
        if total_score > 0:  # åªä¿ç•™æœ‰æ•ˆå¾—åˆ†çš„å‘¨æ¬¡
            records.append({
                'celebrity_name': row['celebrity_name'],
                'ballroom_partner': row['ballroom_partner'],
                'celebrity_industry': row['celebrity_industry'],
                'celebrity_age': row['celebrity_age_during_season'],
                'season': row['season'],
                'week': week,
                'total_score': total_score,
                'final_placement': row['placement'],
                'elimination_week': row['elimination_week']
            })

weekly_data = pd.DataFrame(records)
# ç»“æœ: ~2500 æ¡å‘¨çº§åˆ«è®°å½•
```

#### Step 5: èµ›å­£-å‘¨æ¬¡åˆ†ç»„

åˆ›å»ºä¾¿äºæŸ¥è¯¢çš„æ•°æ®ç»“æ„ï¼š

```python
# å­—å…¸: (season, week) â†’ è¯¥å‘¨æ‰€æœ‰æ´»è·ƒé€‰æ‰‹çš„DataFrame
season_week_data = {}
for (season, week), group in weekly_data.groupby(['season', 'week']):
    season_week_data[(season, week)] = group.copy()

# ç¤ºä¾‹: season_week_data[(27, 9)] è¿”å›ç¬¬27å­£ç¬¬9å‘¨çš„æ‰€æœ‰é€‰æ‰‹æ•°æ®
```

### æ•°æ®ç‰¹æ®Šå€¼å¤„ç†

| åŸå§‹å€¼ | å«ä¹‰ | å¤„ç†æ–¹å¼ |
|--------|------|----------|
| `N/A` | æ— ç¬¬4è¯„å§”æˆ–æ•°æ®ç¼ºå¤± | è½¬ä¸º NaNï¼Œè®¡ç®—æ—¶è·³è¿‡ |
| `0` | é€‰æ‰‹å·²è¢«æ·˜æ±° | è·³è¿‡è¯¥å‘¨æ•°æ® |
| å°æ•° (å¦‚ `8.5`) | å¤šèˆè¡¨æ¼”çš„å¹³å‡åˆ† | ç›´æ¥ä½¿ç”¨ |
| ç©ºç™½ | æ•°æ®ç¼ºå¤± | è½¬ä¸º NaN |

### æ·˜æ±°ä¿¡æ¯æå–

```python
# æå–æ¯å‘¨çš„æ·˜æ±°è®°å½•
elimination_info = []
for _, row in df.iterrows():
    elim_week = row['elimination_week']
    if elim_week is not None:
        elimination_info.append({
            'season': row['season'],
            'week': elim_week,
            'eliminated_name': row['celebrity_name'],
            'eliminated_placement': row['placement'],
            'final_score': row[f'week{elim_week}_total']
        })

elimination_df = pd.DataFrame(elimination_info)
# ç»“æœ: ~380 æ¡æ·˜æ±°è®°å½•
```

---

## ğŸ“Š æ•°å­¦æ¨¡å‹è¯¦è§£

### æ¨¡å‹1: åŸºçº¿æ¨¡å‹ (Baseline Model)

**æ ¸å¿ƒæ€æƒ³**ï¼šè§‚ä¼—æŠ•ç¥¨ä¸è¯„å§”å¾—åˆ†æˆæ­£æ¯”

$$V_i \propto S_i^{\alpha}$$

å…¶ä¸­ï¼š
- $V_i$ï¼šé€‰æ‰‹ $i$ çš„æŠ•ç¥¨æ•°
- $S_i$ï¼šé€‰æ‰‹ $i$ çš„è¯„å§”æ€»åˆ†
- $\alpha$ï¼šå½±å“ç³»æ•°ï¼ˆé€šè¿‡ç½‘æ ¼æœç´¢ä¼˜åŒ–ï¼‰

#### å®ç°é€»è¾‘

```python
def estimate_votes(judge_scores, alpha=1.0, total_votes=1e6):
    """
    åŸºçº¿æŠ•ç¥¨ä¼°è®¡
    
    Args:
        judge_scores: è¯„å§”å¾—åˆ†æ•°ç»„ [S_1, S_2, ..., S_n]
        alpha: å¹‚æ¬¡å‚æ•°
        total_votes: å‡è®¾çš„æ€»æŠ•ç¥¨æ•°
    
    Returns:
        ä¼°è®¡æŠ•ç¥¨æ•°ç»„ [V_1, V_2, ..., V_n]
    """
    # Step 1: è®¡ç®—åŸºç¡€æŠ•ç¥¨ï¼ˆå¾—åˆ†çš„Î±æ¬¡å¹‚ï¼‰
    base_votes = np.power(judge_scores, alpha)
    
    # Step 2: å½’ä¸€åŒ–åˆ°æ€»ç¥¨æ•°
    votes = base_votes / base_votes.sum() * total_votes
    
    return votes
```

#### å‚æ•°ä¼˜åŒ–

é€šè¿‡ç½‘æ ¼æœç´¢æ‰¾åˆ°æœ€ä¼˜ $\alpha$ï¼š

```python
def fit_alpha(season_week_data, elimination_info):
    """
    ç½‘æ ¼æœç´¢æœ€ä¼˜alpha
    ç›®æ ‡: æœ€å¤§åŒ–æ·˜æ±°é¢„æµ‹å‡†ç¡®ç‡
    """
    alphas = np.arange(0.5, 2.1, 0.1)  # æœç´¢èŒƒå›´
    best_alpha, best_accuracy = 1.0, 0.0
    
    for alpha in alphas:
        accuracy = compute_elimination_accuracy(alpha, season_week_data, elimination_info)
        if accuracy > best_accuracy:
            best_accuracy = accuracy
            best_alpha = alpha
    
    return best_alpha  # é€šå¸¸åœ¨ 0.8-1.2 ä¹‹é—´
```

**ä¼˜ç‚¹**ï¼šç®€å•ç›´è§‚ï¼Œè®¡ç®—å¿«é€Ÿ  
**ç¼ºç‚¹**ï¼šæ— æ³•æ•æ‰è¯„å§”ä¸è§‚ä¼—åå¥½å·®å¼‚

---

### æ¨¡å‹2: çº¦æŸä¼˜åŒ–æ¨¡å‹ (Constrained Optimization)

**æ ¸å¿ƒæ€æƒ³**ï¼šåˆ©ç”¨æ·˜æ±°ç»“æœä½œä¸ºçº¦æŸæ¡ä»¶ï¼Œåæ¨æ»¡è¶³çº¦æŸçš„æŠ•ç¥¨åˆ†å¸ƒ

#### æ•°å­¦å½¢å¼åŒ–

**å†³ç­–å˜é‡**ï¼š$\mathbf{V} = [V_1, V_2, \ldots, V_n]^T$ï¼ˆå„é€‰æ‰‹æŠ•ç¥¨æ•°ï¼‰

**ç›®æ ‡å‡½æ•°**ï¼ˆæœ€å°åŒ–ä¸å…ˆéªŒçš„åå·®ï¼‰ï¼š
$$\min_{\mathbf{V}} \sum_i \left( \log V_i - \log V_i^{\text{prior}} \right)^2$$

å…¶ä¸­å…ˆéªŒ $V_i^{\text{prior}}$ åŸºäºè¯„å§”å¾—åˆ†ï¼š
$$V_i^{\text{prior}} = \frac{\exp(\lambda \cdot S_i / S_{\max})}{\sum_j \exp(\lambda \cdot S_j / S_{\max})} \times N_{\text{total}}$$

#### çº¦æŸæ¡ä»¶

**æ’åæ³•èµ›å­£ (S1-S2, S28-S34)**ï¼š

è®¾ $k$ ä¸ºè¢«æ·˜æ±°é€‰æ‰‹ï¼Œ$R_S(i)$ ä¸ºé€‰æ‰‹ $i$ çš„è¯„å§”æ’åï¼Œ$R_V(i)$ ä¸ºæŠ•ç¥¨æ’åï¼š

$$R_S(k) + R_V(k) \geq R_S(j) + R_V(j), \quad \forall j \neq k$$

å³è¢«æ·˜æ±°è€…çš„ç»¼åˆæ’åå¾—åˆ†ï¼ˆè¶Šé«˜è¶Šå·®ï¼‰å¿…é¡»æœ€å¤§ã€‚

**ç™¾åˆ†æ¯”æ³•èµ›å­£ (S3-S27)**ï¼š

$$\frac{S_k}{\sum_i S_i} + \frac{V_k}{\sum_i V_i} \leq \frac{S_j}{\sum_i S_i} + \frac{V_j}{\sum_i V_i}, \quad \forall j \neq k$$

å³è¢«æ·˜æ±°è€…çš„ç»¼åˆç™¾åˆ†æ¯”å¿…é¡»æœ€å°ã€‚

#### å®ç°é€»è¾‘

```python
def estimate_votes_rank_method(judge_scores, eliminated_idx, total_votes=1e6):
    """
    æ’åæ³•çº¦æŸä¼˜åŒ–
    
    Args:
        judge_scores: è¯„å§”å¾—åˆ†æ•°ç»„
        eliminated_idx: è¢«æ·˜æ±°é€‰æ‰‹çš„ç´¢å¼•
        total_votes: æ€»æŠ•ç¥¨æ•°
    """
    n = len(judge_scores)
    prior = compute_prior_votes(judge_scores, total_votes)
    
    # ç›®æ ‡å‡½æ•°: æœ€å°åŒ–å¯¹æ•°ç©ºé—´åå·®
    def objective(votes):
        log_votes = np.log(votes + 1)
        log_prior = np.log(prior + 1)
        return np.sum((log_votes - log_prior) ** 2)
    
    # çº¦æŸ: è¢«æ·˜æ±°è€…ç»¼åˆæ’åæœ€å·®
    def elimination_constraint(votes):
        # è®¡ç®—ç»¼åˆæ’åå¾—åˆ† (è¶Šé«˜è¶Šå·®)
        combined = compute_rank_combined_score(judge_scores, votes)
        eliminated_score = combined[eliminated_idx]
        max_other_score = max(combined[i] for i in range(n) if i != eliminated_idx)
        return eliminated_score - max_other_score  # å¿…é¡» >= 0
    
    # è¾¹ç•Œçº¦æŸ
    bounds = [(100, total_votes * 0.8) for _ in range(n)]
    
    # ç­‰å¼çº¦æŸ: æ€»ç¥¨æ•°
    constraints = [
        {'type': 'ineq', 'fun': elimination_constraint},
        {'type': 'eq', 'fun': lambda v: np.sum(v) - total_votes}
    ]
    
    # SLSQPä¼˜åŒ–
    result = minimize(objective, prior, method='SLSQP', 
                     bounds=bounds, constraints=constraints)
    
    return result.x
```

#### ç»¼åˆå¾—åˆ†è®¡ç®—

```python
def compute_rank_combined_score(judge_scores, fan_votes):
    """
    æ’åæ³•ç»¼åˆå¾—åˆ† (è¶Šé«˜è¶Šå·®ï¼Œæœ€é«˜è€…è¢«æ·˜æ±°)
    """
    # è¯„å§”æ’å (å¾—åˆ†æœ€é«˜ â†’ æ’å1)
    judge_ranks = np.argsort(np.argsort(-judge_scores)) + 1
    # æŠ•ç¥¨æ’å (ç¥¨æ•°æœ€é«˜ â†’ æ’å1)
    fan_ranks = np.argsort(np.argsort(-fan_votes)) + 1
    # ç»¼åˆ = ä¸¤æ’åä¹‹å’Œ
    return judge_ranks + fan_ranks

def compute_percent_combined_score(judge_scores, fan_votes):
    """
    ç™¾åˆ†æ¯”æ³•ç»¼åˆå¾—åˆ† (è¶Šé«˜è¶Šå¥½ï¼Œæœ€ä½è€…è¢«æ·˜æ±°)
    """
    judge_pct = judge_scores / judge_scores.sum()
    fan_pct = fan_votes / fan_votes.sum()
    return judge_pct + fan_pct
```

**ä¼˜åŒ–æ–¹æ³•**ï¼šSLSQP (Sequential Least Squares Programming)

**ä¼˜ç‚¹**ï¼šä¿è¯ä¸æ·˜æ±°ç»“æœä¸€è‡´  
**ç¼ºç‚¹**ï¼šè§£å¯èƒ½ä¸å”¯ä¸€

---

### æ¨¡å‹3: è´å¶æ–¯å±‚æ¬¡æ¨¡å‹ (Bayesian Hierarchical Model)

**æ ¸å¿ƒæ€æƒ³**ï¼šä½¿ç”¨å®Œæ•´çš„è´å¶æ–¯æ¨æ–­ï¼Œå»ºæ¨¡é€‰æ‰‹ã€èˆä¼´ã€èµ›å­£ç­‰å¤šå±‚æ¬¡éšæœºæ•ˆåº”

#### æ¨¡å‹ç»“æ„

**è§‚æµ‹å±‚**ï¼š
$$\log(V_{i,w}) \sim \mathcal{N}(\mu_{i,w}, \sigma^2)$$

**çº¿æ€§é¢„æµ‹å™¨**ï¼š
$$\mu_{i,w} = \beta_0 + \beta_1 \cdot \tilde{S}_{i,w} + \beta_2 \cdot \tilde{A}_i + \alpha_{p[i]} + \gamma_{s[i]} + \delta_{d[i]}$$

å…¶ä¸­ï¼š
- $\tilde{S}_{i,w} = (S_{i,w} - \bar{S}) / \sigma_S$ï¼šæ ‡å‡†åŒ–è¯„å§”å¾—åˆ†
- $\tilde{A}_i = (A_i - \bar{A}) / \sigma_A$ï¼šæ ‡å‡†åŒ–å¹´é¾„
- $\alpha_{p[i]}$ï¼šé€‰æ‰‹ $i$ çš„èˆä¼´ $p[i]$ çš„éšæœºæ•ˆåº”
- $\gamma_{s[i]}$ï¼šèµ›å­£ $s[i]$ çš„éšæœºæ•ˆåº”
- $\delta_{d[i]}$ï¼šè¡Œä¸š $d[i]$ çš„éšæœºæ•ˆåº”

#### å…ˆéªŒåˆ†å¸ƒ

| å‚æ•° | å…ˆéªŒ | è¯´æ˜ |
|------|------|------|
| $\beta_0$ | $\mathcal{N}(10, 2)$ | æˆªè·ï¼ˆå¯¹æ•°å°ºåº¦ï¼‰ |
| $\beta_1$ | $\mathcal{N}(0, 0.5)$ | å¾—åˆ†ç³»æ•° |
| $\beta_2$ | $\mathcal{N}(0, 0.1)$ | å¹´é¾„ç³»æ•° |
| $\sigma$ | $\text{HalfNormal}(1)$ | æ®‹å·®æ ‡å‡†å·® |
| $\sigma_p$ | $\text{HalfNormal}(0.5)$ | èˆä¼´æ•ˆåº”æ ‡å‡†å·® |
| $\sigma_s$ | $\text{HalfNormal}(0.3)$ | èµ›å­£æ•ˆåº”æ ‡å‡†å·® |
| $\sigma_d$ | $\text{HalfNormal}(0.5)$ | è¡Œä¸šæ•ˆåº”æ ‡å‡†å·® |
| $\alpha_{p}$ | $\mathcal{N}(0, \sigma_p)$ | èˆä¼´éšæœºæ•ˆåº” |
| $\gamma_{s}$ | $\mathcal{N}(0, \sigma_s)$ | èµ›å­£éšæœºæ•ˆåº” |
| $\delta_{d}$ | $\mathcal{N}(0, \sigma_d)$ | è¡Œä¸šéšæœºæ•ˆåº” |

#### PyMC å®ç°

```python
import pymc as pm

with pm.Model() as vote_model:
    # ========== è¶…å…ˆéªŒ ==========
    sigma_partner = pm.HalfNormal('sigma_partner', sigma=0.5)
    sigma_season = pm.HalfNormal('sigma_season', sigma=0.3)
    sigma_industry = pm.HalfNormal('sigma_industry', sigma=0.5)
    
    # ========== å›ºå®šæ•ˆåº” ==========
    beta_0 = pm.Normal('beta_0', mu=10, sigma=2)
    beta_score = pm.Normal('beta_score', mu=0, sigma=0.5)
    beta_age = pm.Normal('beta_age', mu=0, sigma=0.1)
    
    # ========== éšæœºæ•ˆåº” ==========
    alpha_partner = pm.Normal('alpha_partner', mu=0, sigma=sigma_partner,
                              shape=n_partners)
    gamma_season = pm.Normal('gamma_season', mu=0, sigma=sigma_season,
                             shape=n_seasons)
    delta_industry = pm.Normal('delta_industry', mu=0, sigma=sigma_industry,
                               shape=n_industries)
    
    # ========== æ®‹å·® ==========
    sigma = pm.HalfNormal('sigma', sigma=1)
    
    # ========== çº¿æ€§é¢„æµ‹å™¨ ==========
    mu = (beta_0 + 
          beta_score * scores_normalized +
          beta_age * ages_normalized +
          alpha_partner[partner_idx] +
          gamma_season[season_idx] +
          delta_industry[industry_idx])
    
    # ========== ä¼¼ç„¶å‡½æ•° ==========
    log_votes = pm.Normal('log_votes', mu=mu, sigma=sigma, shape=n_obs)
    
    # ========== MCMCé‡‡æ · ==========
    trace = pm.sample(draws=2000, tune=1000, chains=2, 
                      random_seed=42, return_inferencedata=True)
```

#### åéªŒé¢„æµ‹

```python
def sample_votes_posterior(contestants, n_samples=1000):
    """
    ä»åéªŒåˆ†å¸ƒé‡‡æ ·æŠ•ç¥¨
    """
    samples = np.zeros((n_samples, len(contestants)))
    
    # ä»åéªŒä¸­éšæœºæŠ½å–å‚æ•°ç»„åˆ
    for s in range(n_samples):
        # æŠ½å–å‚æ•°
        beta_0 = posterior_samples['beta_0'][s]
        beta_score = posterior_samples['beta_score'][s]
        # ... å…¶ä»–å‚æ•°
        
        for i, row in contestants.iterrows():
            # è®¡ç®—æœŸæœ›å¯¹æ•°æŠ•ç¥¨
            mu = (beta_0 + 
                  beta_score * normalize(row['total_score']) +
                  alpha_partner[row['partner_idx']] +
                  gamma_season[row['season_idx']])
            
            # é‡‡æ ·
            log_vote = np.random.normal(mu, sigma)
            samples[s, i] = np.exp(log_vote)
        
        # å½’ä¸€åŒ–åˆ°æ€»ç¥¨æ•°
        samples[s] = samples[s] / samples[s].sum() * total_votes
    
    return samples
```

#### MCMC è¯Šæ–­

```python
# æ”¶æ•›è¯Šæ–­
print(az.summary(trace, var_names=['beta_0', 'beta_score', 'sigma']))

# æ£€æŸ¥é¡¹ç›®:
# - R-hat â‰ˆ 1.0 (< 1.01 ä¸ºä½³): é“¾é—´æ”¶æ•›
# - ESS > 400: æœ‰æ•ˆæ ·æœ¬é‡
# - æ— å‘æ•£ (divergences = 0)
```

**æ¨æ–­æ–¹æ³•**ï¼šPyMC + NUTS (No-U-Turn Sampler) MCMC

**ä¼˜ç‚¹**ï¼š
- å®Œæ•´çš„ä¸ç¡®å®šæ€§é‡åŒ–
- è‡ªåŠ¨å­¦ä¹ éšæœºæ•ˆåº”
- å¯è§£é‡Šçš„å±‚æ¬¡ç»“æ„

**ç¼ºç‚¹**ï¼šè®¡ç®—é‡è¾ƒå¤§

---

## ğŸ”„ æŠ•ç¥¨ä¼°è®¡å™¨æ•´åˆ

`VoteEstimator` ç±»æ•´åˆä¸‰ç§æ¨¡å‹ï¼Œæä¾›ç»Ÿä¸€æ¥å£ï¼š

```python
class VoteEstimator:
    def __init__(self, model_type='ensemble'):
        """
        model_type: 'baseline', 'constrained', 'bayesian', 'ensemble'
        """
        self.baseline = BaselineModel()
        self.constrained = ConstrainedOptimizationModel()
        self.bayesian = BayesianVoteModel()
        
        # é›†æˆæƒé‡
        self.weights = {'baseline': 0.2, 'constrained': 0.5, 'bayesian': 0.3}
    
    def estimate(self, season_week_data, elimination_info):
        """
        é›†æˆä¼°è®¡: åŠ æƒå¹³å‡ä¸‰ç§æ¨¡å‹çš„ç»“æœ
        """
        v_baseline = self.baseline.estimate_all_weeks(season_week_data)
        v_constrained = self.constrained.estimate_all_weeks(season_week_data, elimination_info)
        v_bayesian = self.bayesian.estimate_all_weeks(season_week_data)
        
        ensemble = {}
        for key in season_week_data.keys():
            ensemble[key] = (
                self.weights['baseline'] * v_baseline[key] +
                self.weights['constrained'] * v_constrained[key] +
                self.weights['bayesian'] * v_bayesian[key]
            )
        
        return ensemble
```

---

## ğŸ“ˆ æ¨¡å‹è¯„ä¼°æŒ‡æ ‡

### 1. ä¸€è‡´æ€§æ£€éªŒ (Consistency Check)

éªŒè¯ä¼°è®¡çš„æŠ•ç¥¨æ˜¯å¦èƒ½æ­£ç¡®é¢„æµ‹æ·˜æ±°ç»“æœï¼š

$$\text{Accuracy} = \frac{\text{æ­£ç¡®é¢„æµ‹çš„æ·˜æ±°æ•°}}{\text{æ€»æ·˜æ±°å‘¨æ¬¡æ•°}}$$

#### å®ç°é€»è¾‘

```python
def check_elimination_consistency(estimates, elimination_info):
    """
    æ£€éªŒæ¯å‘¨æ·˜æ±°é¢„æµ‹çš„æ­£ç¡®æ€§
    """
    results = []
    
    for (season, week), est in estimates.items():
        # è·å–å®é™…æ·˜æ±°è€…
        actual = elimination_info.query(f'season=={season} and week=={week}')
        if len(actual) == 0:
            continue
        actual_name = actual.iloc[0]['eliminated_name']
        
        # é¢„æµ‹æ·˜æ±°è€…
        scores, votes = est['scores'], est['votes']
        
        if season in RANK_SEASONS:
            combined = compute_rank_combined_score(scores, votes)
            pred_idx = np.argmax(combined)  # æœ€é«˜è€…è¢«æ·˜æ±°
        else:
            combined = compute_percent_combined_score(scores, votes)
            pred_idx = np.argmin(combined)  # æœ€ä½è€…è¢«æ·˜æ±°
        
        pred_name = est['names'][pred_idx]
        
        results.append({
            'season': season,
            'week': week,
            'actual': actual_name,
            'predicted': pred_name,
            'is_correct': actual_name == pred_name
        })
    
    return pd.DataFrame(results)
```

**åº•2å‡†ç¡®ç‡**ï¼šè¢«æ·˜æ±°é€‰æ‰‹æ˜¯å¦åœ¨é¢„æµ‹çš„æœ€åä¸¤åä¸­

### 2. ä¸ç¡®å®šæ€§åº¦é‡ (Uncertainty Measure)

#### ä»åéªŒæ ·æœ¬è®¡ç®—

```python
def compute_uncertainty(samples):
    """
    samples: (n_samples, n_contestants)
    """
    mean = samples.mean(axis=0)
    std = samples.std(axis=0)
    
    # å˜å¼‚ç³»æ•°
    cv = std / mean
    
    # 95% å¯ä¿¡åŒºé—´
    ci_lower = np.percentile(samples, 2.5, axis=0)
    ci_upper = np.percentile(samples, 97.5, axis=0)
    ci_width = ci_upper - ci_lower
    
    # ç¡®å®šæ€§åˆ†ç±»
    certainty = np.where(cv < 0.1, 'High',
                np.where(cv < 0.3, 'Medium', 'Low'))
    
    return {
        'mean': mean,
        'std': std,
        'cv': cv,
        'ci_lower': ci_lower,
        'ci_upper': ci_upper,
        'certainty': certainty
    }
```

**å˜å¼‚ç³»æ•° (CV)**ï¼š
$$CV = \frac{\sigma_V}{\mu_V}$$

**ç¡®å®šæ€§åˆ†ç±»**ï¼š
| CV èŒƒå›´ | ç¡®å®šæ€§ç­‰çº§ |
|---------|-----------|
| CV < 0.1 | é«˜ (High) |
| 0.1 â‰¤ CV < 0.3 | ä¸­ (Medium) |
| CV â‰¥ 0.3 | ä½ (Low) |

### 3. æ’åç›¸å…³æ€§

```python
from scipy import stats

def compute_rank_correlations(judge_scores, estimated_votes):
    """
    è®¡ç®—è¯„å§”æ’åä¸æŠ•ç¥¨æ’åçš„ç›¸å…³æ€§
    """
    score_ranks = np.argsort(np.argsort(-judge_scores)) + 1
    vote_ranks = np.argsort(np.argsort(-estimated_votes)) + 1
    
    # Kendall's Ï„
    tau, p_tau = stats.kendalltau(score_ranks, vote_ranks)
    
    # Spearman's Ï  
    rho, p_rho = stats.spearmanr(score_ranks, vote_ranks)
    
    return {'kendall_tau': tau, 'spearman_rho': rho}
```

- **Kendall's Ï„**ï¼šè¯„å§”æ’åä¸æŠ•ç¥¨æ’åçš„ç›¸å…³æ€§
- **Spearman's Ï**ï¼šç­‰çº§ç›¸å…³ç³»æ•°

---

## ğŸ“ è¾“å‡ºæ–‡ä»¶è¯´æ˜

| æ–‡ä»¶ | è¯´æ˜ |
|------|------|
| `vote_estimates.csv` | æ¯ä½é€‰æ‰‹æ¯å‘¨çš„æŠ•ç¥¨ä¼°è®¡å€¼ |
| `consistency_results.csv` | æ¯å‘¨æ·˜æ±°é¢„æµ‹çš„æ­£ç¡®æ€§ |
| `incorrect_predictions.csv` | é¢„æµ‹é”™è¯¯çš„æ¡ˆä¾‹åˆ†æ |
| `figures/` | å¯è§†åŒ–å›¾è¡¨ç›®å½• |

### vote_estimates.csv å­—æ®µ

| å­—æ®µ | è¯´æ˜ |
|------|------|
| `season` | èµ›å­£ç¼–å· |
| `week` | å‘¨æ¬¡ |
| `celebrity_name` | é€‰æ‰‹å§“å |
| `judge_score` | è¯„å§”æ€»åˆ† |
| `estimated_votes` | ä¼°è®¡æŠ•ç¥¨æ•° |

---

## ğŸ¨ å¯è§†åŒ–è¾“å‡º

ç¨‹åºè‡ªåŠ¨ç”Ÿæˆä»¥ä¸‹å›¾è¡¨ï¼š

1. **æŠ•ç¥¨ä¼°è®¡æŸ±çŠ¶å›¾**ï¼šå±•ç¤ºå„é€‰æ‰‹çš„ä¼°è®¡æŠ•ç¥¨ä¸è¯„å§”å¾—åˆ†å¯¹æ¯”
2. **ç½®ä¿¡åŒºé—´å›¾**ï¼šå¸¦95%å¯ä¿¡åŒºé—´çš„æŠ•ç¥¨ä¼°è®¡
3. **ä¸€è‡´æ€§çƒ­åŠ›å›¾**ï¼šå„èµ›å­£å„å‘¨çš„é¢„æµ‹å‡†ç¡®ç‡
4. **ä¸ç¡®å®šæ€§åˆ†å¸ƒå›¾**ï¼šCVåˆ†å¸ƒä¸ç¡®å®šæ€§ç­‰çº§å æ¯”
5. **å‡†ç¡®ç‡æ±‡æ€»å›¾**ï¼šæ€»ä½“ä¸åˆ†èµ›å­£çš„é¢„æµ‹å‡†ç¡®ç‡

---

## ğŸ”¬ äº‰è®®æ¡ˆä¾‹åˆ†æ

æ¨¡å‹ç‰¹åˆ«å…³æ³¨ä»¥ä¸‹äº‰è®®èµ›å­£ï¼š

| èµ›å­£ | äº‰è®®é€‰æ‰‹ | ç°è±¡ |
|------|---------|------|
| S2 | Jerry Rice | å¾—åˆ†é«˜ä½†æ„å¤–æ·˜æ±° |
| S4 | Billy Ray Cyrus | å¾—åˆ†ä½ä½†è¿›å…¥å†³èµ› |
| S11 | Bristol Palin | å¾—åˆ†å«åº•ä½†è·ç¬¬ä¸‰å |
| S27 | Bobby Bones | ä½åˆ†å¤ºå† å¼•å‘äº‰è®® |

è¿™äº›æ¡ˆä¾‹åæ˜ äº†è¯„å§”è¯„åˆ†ä¸è§‚ä¼—æŠ•ç¥¨çš„æ˜¾è‘—åˆ†æ­§ï¼Œæ˜¯éªŒè¯æ¨¡å‹çš„é‡è¦æµ‹è¯•é›†ã€‚

---

## âš™ï¸ é…ç½®å‚æ•°

åœ¨ `config.py` ä¸­å¯è°ƒæ•´ä»¥ä¸‹å‚æ•°ï¼š

```python
# æ¨¡å‹é…ç½®
class ModelConfig:
    OPTIMIZATION_METHOD = 'SLSQP'    # ä¼˜åŒ–æ–¹æ³•
    OPTIMIZATION_MAX_ITER = 1000     # æœ€å¤§è¿­ä»£æ¬¡æ•°
    MCMC_SAMPLES = 2000              # MCMCé‡‡æ ·æ•°
    MCMC_TUNE = 1000                 # è°ƒä¼˜æ­¥æ•°
    MCMC_CHAINS = 2                  # é©¬å°”å¯å¤«é“¾æ•°
    RANDOM_SEED = 42                 # éšæœºç§å­
```

---

## ğŸ“š å‚è€ƒæ–‡çŒ®

1. Gelman, A., et al. (2013). *Bayesian Data Analysis*. CRC Press.
2. Salvatier, J., et al. (2016). Probabilistic programming in Python using PyMC3.
3. Boyd, S., & Vandenberghe, L. (2004). *Convex Optimization*. Cambridge University Press.

---

## ğŸ“ è®¸å¯è¯

æœ¬é¡¹ç›®ä»…ç”¨äº 2026 MCM æ•°å­¦å»ºæ¨¡ç«èµ›ã€‚

---

## ğŸ‘¥ è´¡çŒ®è€…

yanxiao å›¢é˜Ÿ
