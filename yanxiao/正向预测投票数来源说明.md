# 正向预测时投票数的来源说明

## 🔄 完整工作流程

```
阶段1: 训练阶段（反推投票）
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
输入数据:
  - 评委分数: [25, 28, 26]
  - 实际淘汰者: A ✓

↓ model.fit()

[约束优化反推]
  目标函数:
    ① 投票份额接近"评分归一化 × (1 + 先验偏好)"
    ② 确保被淘汰者A的综合得分最差
  
  优化求解:
    votes_A = 100,000   ← 给A少点票
    votes_B = 450,000   ← 给B多点票
    votes_C = 450,000   ← 给C多点票

↓ 保存到 self.results_df

results_df:
┌─────────┬──────┬──────────┬────────┬────────────────┐
│ season  │ week │ celebrity│ score  │ estimated_votes│
├─────────┼──────┼──────────┼────────┼────────────────┤
│   2     │  8   │    A     │   25   │   100,000      │
│   2     │  8   │    B     │   28   │   450,000      │
│   2     │  8   │    C     │   26   │   450,000      │
└─────────┴──────┴──────────┴────────┴────────────────┘

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━


阶段2: 正向预测阶段
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
输入数据:
  - 评委分数: [25, 28, 26]
  - 反推得到的投票数: [100,000, 450,000, 450,000] ← 来自阶段1

↓ consistency_check()

[正向计算综合得分]
  排名法:
    A: judge_rank(3) + vote_rank(3) = 6  ← 最差
    B: judge_rank(1) + vote_rank(1) = 2
    C: judge_rank(2) + vote_rank(2) = 4
  
  预测淘汰者: A (综合排名最高)

↓ 对比实际结果

实际淘汰者: A
预测淘汰者: A
→ 预测正确! ✓

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
```

---

## 💡 关键要点

### Q1: 正向预测的投票数从哪来？
**A**: 来自训练阶段的**约束优化反推结果**

```python
# 训练阶段：反推投票
model.fit(weekly_data, elimination_info)
  → _solve_all_weeks()
    → _solve_votes_for_week()  # 对每周用约束优化反推
      → 保存到 self.results_df['estimated_votes']

# 获取投票估计
estimates = model.get_estimates_dict()
  → 从 self.results_df 中提取
  → estimates[(season, week)]['votes'] = [100000, 450000, 450000]

# 正向预测
consistency_check(estimates, ...)
  → 使用 estimates 中的投票数
  → 正向计算综合得分
  → 预测谁会被淘汰
```

---

## 🎯 约束优化如何反推投票？

### 优化目标函数

```python
def objective(vote_shares):
    # 1️⃣ 正则化项：投票应该接近先验
    score_based = scores / sum(scores)  # 评分归一化
    prior_votes = score_based × (1 + 先验偏好)
    reg_loss = sum((vote_shares - prior_votes)²)
    
    # 2️⃣ 约束惩罚项：确保淘汰者综合得分最差
    combined = 计算综合得分(scores, vote_shares)
    constraint_violation = 0
    
    for 被淘汰者 in 淘汰列表:
        for 存活者 in 存活列表:
            if 存活者得分 >= 被淘汰者得分:  # 违反约束
                constraint_violation += (差值)²
    
    return reg_loss + 1000 × constraint_violation
```

### 优化约束

```python
bounds: 每个投票份额 ∈ [0.001, 0.999]
constraints: sum(vote_shares) = 1
```

### 先验偏好来源

```python
prior_boost = partner_effects[舞伴] + industry_effects[行业]

例如:
  Emma Slater: +0.764
  健身教练: +0.680
  → 该选手先验偏好 = 0.764 + 0.680 = +1.444
  → 优化时倾向于给更高投票份额
```

---

## 📊 具体例子

### Season 2, Week 8

**输入数据**:
```
选手A: 评分25, 舞伴(普通)+0.1, 行业(演员)+0.2 → 先验+0.3
选手B: 评分28, 舞伴(Emma)+0.8, 行业(健身)+0.7 → 先验+1.5
选手C: 评分26, 舞伴(普通)+0.1, 行业(歌手)+0.3 → 先验+0.4

实际淘汰: A
```

**约束优化过程**:

```python
# 初始猜测（基于评分+先验）
初始投票份额:
  A: 25×(1+0.3) / 总和 = 0.28
  B: 28×(1+1.5) / 总和 = 0.48
  C: 26×(1+0.4) / 总和 = 0.24

# 优化迭代
迭代1: [0.28, 0.48, 0.24] → constraint_violation = 50
迭代2: [0.20, 0.50, 0.30] → constraint_violation = 10
迭代3: [0.15, 0.52, 0.33] → constraint_violation = 0 ✓

# 最终结果
优化后投票份额: [0.15, 0.52, 0.33]
转换为投票数: [150k, 520k, 330k]

# 验证
综合排名(rank法):
  A: rank(3) + rank(3) = 6 ← 最差，会被淘汰 ✓
  B: rank(1) + rank(1) = 2
  C: rank(2) + rank(2) = 4
```

**保存结果**:
```python
results_df.append({
    'season': 2,
    'week': 8,
    'celebrity': 'A',
    'estimated_votes': 150000  # ← 这就是正向预测时用的数据
})
```

---

## 🔍 为什么反推准确率(99%)比正向准确率(88%)高？

### 反推阶段（99.12%）
- ✅ **已知答案**: "A被淘汰了"
- ✅ **自由调整**: 可以调整所有人的投票数
- ✅ **目标明确**: 确保A综合得分最差
- ✅ **容易成功**: 只要结果自洽就行

### 正向预测阶段（87.50%）
- ❌ **未知答案**: 不知道谁被淘汰
- ❌ **固定输入**: 只能用反推得到的投票数
- ❌ **目标模糊**: 要猜对实际淘汰者
- ❌ **容易失败**: 如果反推的投票数不准确，预测就错

---

## ⚠️ 关键洞察

正向预测失败的原因：

1. **先验偏好不准确**
   - 舞伴/行业效应是统计估计，有误差
   - 影响反推时的初始值和正则化目标

2. **排名法规则理解可能有误**（51.52%准确率）
   - 实际节目可能有特殊规则
   - 综合得分计算公式可能不对

3. **数据噪声**
   - 某些周次可能有特殊情况（双人赛、救援等）
   - 观众投票受场外因素影响

---

## 📈 改进方向

提高正向预测准确率的方法：

1. **改进先验偏好估计**
   - 使用更复杂的特征（时间趋势、话题热度）
   - 分赛季/分阶段建模

2. **修正排名法公式**
   - 仔细研究早期和晚期赛季的实际规则
   - 考虑可能的规则变化

3. **引入不确定性**
   - 给每个投票估计一个置信区间
   - 预测时考虑多种可能性

4. **交叉验证**
   - 留一法验证模型
   - 分赛季评估性能
