\newpage
\section{问题1：观众投票估计模型}

\subsection{问题剖析与建模策略}

问题1本质上是一个\textbf{欠定逆问题}（underdetermined inverse problem）：在观众投票这一隐变量缺失的情况下，从淘汰结果和评委得分的联合观测中进行统计推断。这类问题在计量经济学和信号处理领域广泛存在，其核心挑战在于解的非唯一性与模型的可识别性（identifiability）。

\textbf{问题的数学结构}。设第$w$周有$n$名选手，评委得分$\mathbf{S} = (S_1, \ldots, S_n)$可观测，观众投票$\mathbf{V} = (V_1, \ldots, V_n)$不可观测，淘汰结果$E$已知。问题可形式化为：给定映射$f: (\mathbf{S}, \mathbf{V}) \rightarrow E$和观测$({\mathbf{S}, E})$，反推$\mathbf{V}$。由于$|\mathbf{V}| = n$个未知数仅对应1个淘汰约束，系统严重欠定（$n \gg 1$）。

\textbf{可识别性困境}。多个投票分布可产生相同淘汰结果，导致解不唯一。传统方法有二：（1）施加正则化约束（如最大熵、稀疏性），但缺乏投票行为的先验支持；（2）引入辅助假设（如投票与得分的参数关系），但可能过度简化现实。我们的策略是将两者结合——用行为模型提供软约束，用淘汰结果施加硬约束，在约束空间中搜索最符合经验规律的解。

\textbf{方法演变的影响}。第28季前后投票组合规则的变化（排名法$\leftrightarrow$百分比法）改变了$f$的函数形式，使得相同的$(\mathbf{S}, \mathbf{V})$可能导致不同的$E$。这要求模型具备\textit{规则自适应性}，能够在统一框架下处理两种机制。

基于上述分析，我们设计\textbf{双层贝叶斯框架}：基线层建立$P(\mathbf{V}|\mathbf{S})$的先验分布，反推层通过$P(\mathbf{V}|\mathbf{S}, E)$进行后验推断。这种分层设计既保证了理论严谨性（后验一致性），又具备实践可行性（先验可解释性）。

\subsection{投票组合方法}

不同赛季使用的两种投票组合方法为（相关符号定义见表~\ref{table:notations}）：

\textbf{排名法}（赛季1-2、28-34）：
\begin{equation}
C_i^{\text{rank}} = R_i^{\text{judge}} + R_i^{\text{fan}}
\end{equation}
其中$R_i^{\text{judge}} = \text{rank}(-S_i)$和$R_i^{\text{fan}} = \text{rank}(-V_i)$。综合排名\textit{最高}（即$C_i^{\text{rank}}$最大，表现最差）的选手被淘汰。

\textbf{百分比法}（赛季3-27）：
\begin{equation}
C_i^{\text{percent}} = \frac{S_i}{\sum_{j=1}^n S_j} + \frac{V_i}{\sum_{j=1}^n V_j}
\end{equation}
综合百分比\textit{最低}的选手被淘汰。

\subsection{基线模型：幂律投票假设}

观众投票与评委得分的关系既非完全独立，亦非严格线性。我们提出\textbf{幂律假设}捕捉这种非线性依赖：
\begin{equation}
V_i \propto S_i^\alpha, \quad \hat{V}_i = V_{\text{total}} \cdot \frac{S_i^\alpha}{\sum_{j=1}^n S_j^\alpha}
\end{equation}

指数$\alpha$的经济学解释：当$\alpha > 1$时，高分选手获得超比例支持（"马太效应"）；$\alpha < 1$时体现"同情弱者"；$\alpha = 1$退化为比例模型。通过网格搜索最大化淘汰预测准确率，校准得$\alpha^* \approx 1.2$，印证观众存在温和的"强者偏好"。

不确定性通过蒙特卡洛采样量化：向幂律预测注入15\%高斯噪声，生成100个样本构建95\%置信区间。这为后续分析提供了统计显著性检验的基础。

\subsection{精确反推模型：约束优化框架}

基线模型提供先验分布$P(\mathbf{V}|\mathbf{S})$，但无法保证后验一致性。我们建立约束优化框架，从淘汰结果反推投票的后验分布$P(\mathbf{V}|\mathbf{S}, E)$。

\subsubsection{投票偏好因子的学习}

在优化前，从全局数据学习系统性偏好。定义"存活提升"$B_i^w$衡量评分排名与生存结果的错位程度：
\begin{equation}
B_i^w = \begin{cases}
-(n - R_i^{\text{score}})/n & \text{若被淘汰（评分越高越意外）} \\
(R_i^{\text{score}} - 1)/n & \text{若存活（评分越低越意外）}
\end{cases}
\end{equation}
其中$R_i^{\text{score}}$为选手$i$的评分排名（1=最高分）。

按专业舞伴$p$和名人行业$d$聚合提升值，得效应参数：
\begin{align}
\beta_p &= \frac{1}{|\mathcal{W}_p|} \sum_{w \in \mathcal{W}_p} B_i^w - \mu_{\text{overall}} \\
\gamma_d &= \frac{1}{|\mathcal{W}_d|} \sum_{w \in \mathcal{W}_d} B_i^w - \mu_{\text{overall}}
\end{align}

结合标准化年龄，构建先验偏好因子：
\begin{equation}
\theta_i = \beta_{p(i)} + \gamma_{d(i)} + \delta_{\text{age}} \cdot \frac{\text{age}_i - \mu_{\text{age}}}{\sigma_{\text{age}}}
\end{equation}

这些偏好因子识别了哪些舞伴、行业和年龄段的选手系统性地获得更多或更少的观众支持。正效应表示该因素带来额外投票支持，负效应则相反。

\subsubsection{优化问题的数学构建}

对投票份额$\mathbf{v} = (v_1, \ldots, v_n)$（满足$v_i \in [0,1], \sum v_i = 1$），最小化目标函数：
\begin{equation}
\mathcal{J}(\mathbf{v}) = \left\| \mathbf{v} - \mathbf{v}^{\text{prior}} \right\|_2^2 + \lambda \cdot \mathcal{L}_{\text{elim}}(\mathbf{v})
\end{equation}
其中先验份额为：
\begin{equation}
\mathbf{v}^{\text{prior}} = \text{normalize}\left[\frac{\mathbf{S}}{\sum_j S_j} \odot (1 + \boldsymbol{\theta})\right]
\end{equation}

\textbf{淘汰约束的软化处理}。对于排名法，离散排名函数不可微，我们采用\textbf{sigmoid软排名近似}：
\begin{equation}
\text{SoftRank}_i = n - \sum_{j \neq i} \frac{1}{1 + \exp[(x_j - x_i)/T]}
\end{equation}
其中$x$可以是分数或投票份额，$T$为温度参数（代码中设为0.1）。该函数近似计算"有多少人比$i$差"，温度越小越接近真实排名。

综合软排名为$C_i^{\text{soft}} = \text{SoftRank}_i(\mathbf{S}) + \text{SoftRank}_i(\mathbf{v})$。淘汰约束惩罚项为：
\begin{equation}
\mathcal{L}_{\text{rank}}(\mathbf{v}) = \sum_{\substack{i: E_i=1 \\ j: E_j=0}} \max(0, C_j^{\text{soft}} - C_i^{\text{soft}} + \delta)^2
\end{equation}
其中边际$\delta = 0.5$确保被淘汰者的软排名显著高于存活者。

对于百分比法，约束为：
\begin{equation}
\mathcal{L}_{\text{percent}}(\mathbf{v}) = \sum_{\substack{i: E_i=1 \\ j: E_j=0}} \max(0, C_i - C_j + \epsilon)^2
\end{equation}
其中$C_i = S_i/\sum S_j + v_i$，边际$\epsilon = 0.01$。

\textbf{正则化项的作用}。$\|\mathbf{v} - \mathbf{v}^{\text{prior}}\|_2^2$防止过拟合，在众多满足约束的解中选择最接近先验的那个。权重$\lambda = 1000$通过实验确定，平衡正则化与约束满足。

\subsubsection{SLSQP算法求解}

采用序列最小二乘规划（SLSQP）求解约束优化。该算法适合处理等式约束$\sum v_i = 1$和盒约束$v_i \in [0.001, 0.999]$，基于梯度信息快速收敛。

初始值设为先验$\mathbf{v}^{\text{prior}}$，优化参数为：最大迭代500次，收敛容差$10^{-8}$。成功收敛的判据是目标函数值低于阈值且淘汰约束得到满足。

\textbf{失败案例分析}。对于约束无法满足的周次（优化失败），模型回退到备用估计：
\begin{equation}
\mathbf{v}^{\text{fallback}} = \text{normalize}\left[\frac{\mathbf{S}}{\sum S_j} \odot (1 + 0.3 \cdot \boldsymbol{\theta})\right]
\end{equation}
这些失败案例往往对应评分与淘汰结果存在强矛盾（如高分选手被淘汰），或数据记录异常（多人同时淘汰/无人淘汰）。

\subsection{模型评估与集成策略}

\subsubsection{一致性度量体系}

评估投票估计需要多个互补指标。代码中实现了以下度量：

\textbf{精确匹配准确率}定义为：
\begin{equation}
\text{ACC}_{\text{exact}} = \frac{1}{W} \sum_{w=1}^W \mathbb{1}\left\{ \text{predicted}(w) = \text{actual}(w) \right\}
\end{equation}
衡量能否精准预测每周被淘汰者，这是最严格的标准。

\textbf{底部N准确率}放宽判定条件，检验实际淘汰者是否落入预测的"危险区"（综合得分最低的若干名）。这更符合实际应用——关心"谁有风险"而非"谁一定淘汰"。

\textbf{约束满足边际}量化淘汰的"确定性"：
\begin{equation}
\text{Margin}_k = \min_{i: E_i = 0} |C_k - C_i|
\end{equation}
边际大表示淘汰显著，边际小则属"惊险淘汰"，投票的微小波动即可改变结果。

\subsubsection{集成策略的实现}

代码采用场景感知的模型选择机制：

\textbf{淘汰周次}：优先使用精确反推模型。运行SLSQP优化，若收敛则采用优化结果。

\textbf{非淘汰周次}：使用基线模型结合偏好因子。具体为：
\begin{equation}
\mathbf{v}^{\text{non-elim}} = 0.7 \cdot \mathbf{v}^{\text{baseline}} + 0.3 \cdot \mathbf{v}^{\text{prior}}
\end{equation}
其中$\mathbf{v}^{\text{baseline}}$为基线模型的幂律估计，$\mathbf{v}^{\text{prior}}$为带偏好因子的先验估计。混合比例70:30平衡了统计规律与个体特征。

\textbf{优化失败周次}：回退到备用估计方法。使用评分比例乘以偏好调整因子（权重0.3），确保即使约束无法满足也能提供合理估计。

\subsubsection{不确定性的传播}

对于基线模型，不确定性通过蒙特卡洛采样量化。生成100个带噪声样本（噪声水平15\%），构建95\%置信区间$[\text{Q}_{2.5\%}, \text{Q}_{97.5\%}]$。

对于精确反推模型，不确定性体现在约束满足边际上。边际越小，说明多个投票分布都可能产生相同淘汰结果，估计的唯一性越差。

代码中还实现了标准化残差分析：
\begin{equation}
r_i = \frac{v_i^* - v_i^{\text{prior}}}{\sigma_i^{\text{prior}}}
\end{equation}
其中$v_i^*$为优化得到的估计，$\sigma_i^{\text{prior}}$为先验标准差（通过蒙特卡洛估计）。$|r_i| > 2$被标记为异常，提示该选手的实际投票显著偏离预期。

\subsubsection{双视角可解释性}

集成策略提供理解投票的两个维度：

\begin{itemize}
    \item \textit{基线视角}：揭示"常规投票模式"——若观众按评分、舞伴、行业等因素理性投票，结果应该如何。
    \item \textit{精确视角}：揭示"实际投票需求"——为了产生观察到的淘汰，投票实际上必须是怎样的。
\end{itemize}

两者的偏离$\Delta_i = v_i^* - v_i^{\text{baseline}}$量化"异常程度"。$\Delta$大的周次往往对应争议事件（如人气选手意外被淘汰，或低分选手意外晋级）。这种差异分析为理解节目的争议性结果（如题目提到的Bobby Bones、Jerry Rice等案例）提供了定量工具。




